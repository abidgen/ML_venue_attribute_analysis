{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# ML: Predicting Star Ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Our objective is to predict a new venue's popularity from information available when the venue opens.  We will do this by machine learning from a data set of venue popularities provided by Yelp.  The data set contains meta data about the venue (where it is located, the type of food served, etc.).  It also contains a star rating. Note that the venues are not limited to restaurants. This tutorial will walk you through one way to build a machine learning algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Metrics and scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "For most questions, you are asked to submit your models `predict` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Download and parse the incoming data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The training data are a series of JSON objects, in a Gzipped file. Python supports Gzipped files natively: [`gzip.open`](https://docs.python.org/3/library/gzip.html) has the same interface as `open`, but handles `.gz` files automatically.\n",
    "\n",
    "The built-in `json` package has a `loads` function that converts a JSON string into a Python dictionary. We could call that once for each row of the file. [`ujson`](http://docs.micropython.org/en/latest/library/ujson.html) has the same interface as the built-in `json` package, but is *substantially* faster (at the cost of non-robust handling of malformed JSON). We will use that inside a list comprehension to get a list of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import gzip\n",
    "\n",
    "with gzip.open('yelp_train_academic_dataset_business.json.gz') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "In scikit-learn, the labels to be predicted, in this case, the stars, are always kept in a separate data structure than the features. Let's get in this habit now, by creating a separate list of the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "star_ratings = [row['stars'] for row in data]\n",
    "# star_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "A few things to consider:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "1. The test set used by the grader will be in the same form as `data`. For this miniproject, it will be a list of dictionaries. The models you will build will need to handle data of this type; we'll discuss this more further in the questions.\n",
    "1. You may find it useful to serialize your trained model using either [`dill`](https://pypi.python.org/pypi/dill) or [`joblib`](http://scikit-learn.org/stable/modules/model_persistence.html). That way, you can reload your model after restarting the Jupyter notebook without needing to retrain it.\n",
    "1. There are obvious mistakes in the data; there is no need to try to correct them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 1: city_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The venues belong to different cities.  You can imagine that the ratings in some cities are probably higher than others.  We wish to build an estimator to make a prediction based on this, but first we need to work out the average rating for each city.  For this problem, create a list of tuples (city name, star rating), one for each city in the data set. There are many ways to do this; please feel free to experiment on your own.  If you get stuck, the steps below attempt to guide you through the process.\n",
    "\n",
    "A simple approach is to go through all of the dictionaries in our array, calculating the sum of the star ratings and the number of venues for each city. At the end, we can just divide the stars by the count to get the average. We could create a separate sum and count variable for each city, but that will get tedious quickly. A better approach is to create a dictionary for each. The key will be the city name, and the value the running sum or running count.\n",
    "\n",
    "One slight annoyance of this approach is that we will have to test whether a key exists in the dictionary before adding to the running tally.  The `collections` module's `defaultdict` class works around this by providing default values for keys that haven't been used. Thus, if we do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "star_sum = defaultdict(int)\n",
    "count = defaultdict(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "we can increment any key of `star_sum` or `count` without first worrying whether the key exists. We need to go through the `data` and `star_ratings` list together, which we can do with the `zip` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "for row, stars in zip(data, star_ratings):\n",
    "    # increment the running sum in star_sum\n",
    "    # increment the running count in count\n",
    "    star_sum[row['city']] += stars\n",
    "    count[row['city']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# star_sum ,count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now we can calculate the average ratings.  Again, a dictionary makes a good container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "avg_stars = dict()\n",
    "for city in star_sum:\n",
    "    # calculate average star rating and store in avg_stars\n",
    "    avg_stars[city]= star_sum[city]/count[city]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7127593360958078"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sum(avg_stars.values()) / len(avg_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "There should be 167 different cities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We can get that list of tuples by converting the returned view object from the `items` method into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_stars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlist\u001b[39m(\u001b[43mavg_stars\u001b[49m\u001b[38;5;241m.\u001b[39mitems())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'avg_stars' is not defined"
     ]
    }
   ],
   "source": [
    "list(avg_stars.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 2: city_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now, let's build a custom estimator that will make a prediction based solely on the city of a venue.  It is tempting to hard-code the answers from the previous section into this model, but we're going to resist and do things properly.\n",
    "\n",
    "This custom estimator will have a `fit` method.  It will receive `data` as its argument `X` and `star_ratings` as `y`, and should repeat the calculation of the previous problem there.  Then the `predict` method can look up the average rating for the city of each record it receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class CityRegressor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.avg_stars = dict()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Store the average rating per city in self.avg_stars\n",
    "        star_sum = defaultdict(int)\n",
    "        count = defaultdict(int)\n",
    "        for row, stars in zip(X,y):\n",
    "            star_sum[row['city']] += stars\n",
    "            count[row['city']] += 1\n",
    "\n",
    "        for city in star_sum:\n",
    "            self.avg_stars[city]= star_sum[city]/count[city]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        result =[]\n",
    "        average_star = sum(self.avg_stars.values()) / len(self.avg_stars)\n",
    "        for row in X:\n",
    "            if row['city'] in self.avg_stars:\n",
    "                result.append(self.avg_stars[row['city']])\n",
    "            else:\n",
    "                result.append(average_star)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now we can create an instance of our regressor and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CityRegressor()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_model = CityRegressor()\n",
    "city_model.fit(data, star_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "And let's see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.6702903946388683, 3.75, 3.75, 3.75, 3.75]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_model.predict(data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "There is a problem, however.  What happens if we're asked to estimate the rating of a venue in a city that's not in our training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.6702903946388683, 3.7127593360958078, 3.6457337883959045]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_model.predict([{'city': 'Phoenix'}, {'city': 'Timbuktu'}, {'city': 'Madison'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 3: lat_long_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "You can imagine that a city-based model might not be sufficiently fine-grained. For example, we know that some neighborhoods are trendier than others.  Use the latitude and longitude of a venue as features that help you understand neighborhood dynamics.\n",
    "\n",
    "Since we need to select the appropriate columns from our dictionaries to build our latitude-longitude model, we will have to use scikit-learn's [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html). However, the `ColumnTransformer` works with either NumPy arrays or pandas data frames. While we can convert our training data into a data frame easily, the test set the grader uses is a list of dictionaries. Thus, our first estimator in our workflow should be a transformer that converts a list of dictionaries into a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class ToDataFrame(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Return a pandas data frame from X\n",
    "        return  pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Let's test out the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_data_frame = ToDataFrame()\n",
    "X_t = to_data_frame.fit_transform(data[:5])\n",
    "\n",
    "# Check that our transformer properly transform the input data into a data frame\n",
    "grader.check((X_t == pd.DataFrame(data[:5])).all(axis=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now we are ready to use `ColumnTransformer` and test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "selector = ColumnTransformer([\n",
    "    ('lat_long', 'passthrough', ['latitude','longitude'])\n",
    "])\n",
    "expected = np.array([data[0]['latitude'], data[0]['longitude']])\n",
    "\n",
    "# Check that our selector returns just two columns, the latitude and longitude\n",
    "grader.check((selector.fit_transform(X_t)[0] == expected).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now, let's feed the output of the transformer in to a `KNeighborsRegressor`. As a sanity check, we'll test it with the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4. , 4.2, 4. , 3.8, 4.2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Training the model\n",
    "data_transform = to_data_frame.transform(data)\n",
    "data_transform = selector.fit_transform(data_transform)\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(data_transform, star_ratings)\n",
    "\n",
    "# Making predictions\n",
    "test_data = data[:5]\n",
    "test_data_transform = to_data_frame.transform(test_data)\n",
    "test_data_transform = selector.transform(test_data_transform)\n",
    "knn.predict(test_data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "We are not ready to submit to the grader; there are two things we still need to do:\n",
    "1. Wrap all the steps necessary to go from our data (list of dictionaries) to predicted ratings\n",
    "1. Determine the optimal value for our predictor's hyperparameter\n",
    "\n",
    "For the first point, we will use a pipeline, ensuring that our model applies all the required transformations given the form of the input data. Remember that a pipeline is made with a list of `(step_name, estimator)` tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37938"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# to_data_frame = ToDataFrame()\n",
    "\n",
    "# selector = ColumnTransformer([\n",
    "#     ('lat_long', 'passthrough', ['latitude','longitude'])\n",
    "# ])\n",
    "\n",
    "# knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# parameters = {'n_neighbors':np.arange(90,121)}\n",
    "# knn = KNeighborsRegressor()\n",
    "# grid_knn = GridSearchCV(knn, parameters)\n",
    "\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#         ('to_df',to_data_frame),\n",
    "#         ('selector',selector),\n",
    "#         ('knn_regressor_grid',grid_knn)\n",
    "# ], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "to_data_frame = ToDataFrame()\n",
    "\n",
    "selector = ColumnTransformer([\n",
    "    ('lat_long', 'passthrough', ['latitude','longitude'])\n",
    "])\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "parameters = {'n_neighbors':np.arange(90,121)}\n",
    "knn = KNeighborsRegressor()\n",
    "grid_knn = GridSearchCV(knn, parameters, cv= KFold(n_splits=5, shuffle=True, random_state=1169))\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('to_df',to_data_frame),\n",
    "        ('selector',selector),\n",
    "        ('knn_regressor_grid',grid_knn)\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now let's fit and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 3) Processing to_df, total=   0.2s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing knn_regressor_grid, total=  21.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.90322581, 3.43548387, 3.56989247, 3.6344086 , 3.56451613])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_long_to_star_ratings = pipe\n",
    "\n",
    "lat_long_to_star_ratings.fit(data, star_ratings)\n",
    "lat_long_to_star_ratings.predict(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 93}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_long_to_star_ratings.named_steps['knn_regressor_grid'].best_params_   ###{'n_neighbors': 93}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Let's now focus on the second point. The `KNeighborsRegressor` takes the `n_neighbors` hyperparameter, which tells it how many nearest neighbors to average together when making a prediction. There is no reason to believe that 5 is the optimum value. We will need to determine a better value for this hyperparameter. A common approach is to use a hyperparameter searching tool such as [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). You may need to refer back to the notebooks about the ways to interface searching tools and pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "You should consider whether the data needs to be shuffled as it might not have been randomized. For example, the data could be ordered by a certain feature or by the labels. If you perform a train/test split with [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split), the data is shuffled by default. However, when using `GridSearchCV`, the folds are not shuffled when you use the default K-folds cross-validation.\n",
    "\n",
    "The code below will plot a rolling mean of the star ratings. Do you need to shuffle the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import Series\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(Series.rolling(Series(star_ratings), window=1000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 4: category_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "While location is important, we could also try seeing how predictive the\n",
    "venue's category is. Build an estimator that considers only the `'categories'` field of the data.\n",
    "\n",
    "The categories come as a list of strings, but the scikit-learn's predictors all need numeric input. We ultimately want to create a column in our feature matrix to represent every category. For a given row, only the columns that represent the categories it contains will be filled with a one, otherwise, it will be filled with a zero. The described method is similar to **one-hot encoding**, however, an observation/row can contain more than one \"hot\", non-zero, column.\n",
    "\n",
    "To achieve our encoding plan, we need to use scikit-learn's provides [`DictVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html#sklearn.feature_extraction.DictVectorizer). This transformer takes a 1-D array of dictionaries and creates a column in the output matrix for each key in the dictionary and fills it with the value associated with it. Missing keys are filled with zeros. However, we need to build a transformer that takes an array of strings and returns an array of dictionaries with keys given by those strings and values of one. For example, it should transform `X_in` into `X_out`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [a]\n",
      "1    [b, c]\n",
      "dtype: object\n",
      "0            {'a': 1}\n",
      "1    {'b': 1, 'c': 1}\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_in = pd.Series([['a'], ['b', 'c']])\n",
    "X_out = pd.Series([{'a': 1}, {'b': 1, 'c': 1}])\n",
    "\n",
    "print(X_in)\n",
    "print(X_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "class DictEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # X will be a pandas series. Return a pandas series of dictionaries\n",
    "        return pd.Series([{i:1 for i in j} for j in X.squeeze()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now let's test out that our `DictEncoder` works out as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(DictEncoder().fit_transform(X_in)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that DictEncoder transforms a series of list of strings into the expected series of dictionaries\n",
    "grader.check((DictEncoder().fit_transform(X_in) == X_out).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now, create a pipeline object of the two step transformation for the categories data. Afterwards, create a `ColumnTransformer` object that will use the aforementioned pipeline object to transform the `'categories'` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dict_vectorizer = Pipeline([\n",
    "        ('DictEncoder',DictEncoder()),\n",
    "        (' DictVectorizer', DictVectorizer())\n",
    "], verbose=True)\n",
    "\n",
    "\n",
    "cat_transformer = ColumnTransformer([\n",
    "    ('dict_vectorize', dict_vectorizer, ['categories'])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Finally, create a pipeline object that will\n",
    "1. Convert our list of dictionaries into a data frame\n",
    "1. Select the `'categories'` column and encode the data\n",
    "1. Train a regularized linear model such as `Ridge`\n",
    "\n",
    "There will be a large number of features, one for each category, so there is a significant danger of overfitting. Use cross validation to choose the best regularization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 4) Processing to_df, total=   0.2s\n",
      "[Pipeline] ....... (step 1 of 2) Processing DictEncoder, total=   0.0s\n",
      "[Pipeline] ... (step 2 of 2) Processing  DictVectorizer, total=   0.1s\n",
      "[Pipeline] ... (step 2 of 4) Processing cat_transformer, total=   0.2s\n",
      "[Pipeline] .. (step 3 of 4) Processing TfidfTransformer, total=   0.0s\n",
      "[Pipeline] ........ (step 4 of 4) Processing ridge_grid, total=  17.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('to_df', ToDataFrame()),\n",
       "                ('cat_transformer',\n",
       "                 ColumnTransformer(transformers=[('dict_vectorize',\n",
       "                                                  Pipeline(steps=[('DictEncoder',\n",
       "                                                                   DictEncoder()),\n",
       "                                                                  (' '\n",
       "                                                                   'DictVectorizer',\n",
       "                                                                   DictVectorizer())],\n",
       "                                                           verbose=True),\n",
       "                                                  ['categories'])])),\n",
       "                ('TfidfTransformer', TfidfTransformer()),\n",
       "                ('ridge_grid',\n",
       "                 GridSearchCV(estimator=Ridge(),\n",
       "                              param_grid={'alpha': array([1.00000000e...\n",
       "       2.32995181e-04, 4.29193426e-04, 7.90604321e-04, 1.45634848e-03,\n",
       "       2.68269580e-03, 4.94171336e-03, 9.10298178e-03, 1.67683294e-02,\n",
       "       3.08884360e-02, 5.68986603e-02, 1.04811313e-01, 1.93069773e-01,\n",
       "       3.55648031e-01, 6.55128557e-01, 1.20679264e+00, 2.22299648e+00,\n",
       "       4.09491506e+00, 7.54312006e+00, 1.38949549e+01, 2.55954792e+01,\n",
       "       4.71486636e+01, 8.68511374e+01, 1.59985872e+02, 2.94705170e+02,\n",
       "       5.42867544e+02, 1.00000000e+03])}))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "\n",
    "n_alphas = 50\n",
    "alphas = np.logspace(-10, 3, n_alphas)\n",
    "\n",
    "parameters = {'alpha': alphas}\n",
    "ridge_ = Ridge()\n",
    "ridge_grid = GridSearchCV(ridge_, parameters)\n",
    "\n",
    "\n",
    "\n",
    "category_model = Pipeline([\n",
    "        ('to_df',to_data_frame),\n",
    "        ('cat_transformer',cat_transformer),\n",
    "        ('TfidfTransformer',TfidfTransformer()),\n",
    "        ('ridge_grid',ridge_grid)\n",
    "], verbose=True)\n",
    "\n",
    "\n",
    "category_model.fit(data, star_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "**Extension:** Some categories (e.g., Restaurants) are not very specific. Others (Japanese sushi) are much more so.  One way to deal with this is with an measure call term frequency-inverse document frequency (tf-idf). Add in a [`TfidfTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) between the `DictVectorizer` and the linear model, and see if that improves performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 5: attribute_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "There is even more information in the attributes for each venue.  Let's build an estimator based on these.\n",
    "\n",
    "Venues attributes may be nested:\n",
    "```python\n",
    "{\n",
    "  'Attire': 'casual',\n",
    "  'Accepts Credit Cards': True,\n",
    "  'Ambiance': {'casual': False, 'classy': False}\n",
    "}\n",
    "```\n",
    "We wish to encode them in the same manner as our categories data using the `DictVectorizer`. Before we do so, we need to flatten the dictionary to a single level:\n",
    "```python\n",
    "{\n",
    "  'Attire_casual' : 1,\n",
    "  'Accepts Credit Cards': 1,\n",
    "  'Ambiance_casual': 0,\n",
    "  'Ambiance_classy': 0\n",
    "}\n",
    "```\n",
    "Build a custom transformer that flattens the dictionary for the `'attributes'` field. Similar to what was done before, create a model that properly encodes the attribute data and learns to predict the ratings.\n",
    "\n",
    "You may find it difficult to find a single regressor that does well enough. A common solution is to use a linear model to fit the linear part of some data, and use a non-linear model to fit the residual that the linear model can't fit. Build a custom predictor that takes as an argument two other predictors. It should use the first to fit the raw data and the second to fit the residuals of the first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections.abc import MutableMapping\n",
    "\n",
    "# def dict_flattener(X: MutableMapping):\n",
    "#     parent_key = str()\n",
    "#     sep = '_'\n",
    "#     items= []\n",
    "#     for k, v in X.items():\n",
    "#         new_key = (parent_key + sep + str(k)) if parent_key else str(k)\n",
    "#         if isinstance(v, MutableMapping):\n",
    "#             items.extend(dict_flattener(v).items())\n",
    "#         elif isinstance(v,bool):\n",
    "#             items.append((new_key, int(v)))\n",
    "#         elif isinstance(v,str):\n",
    "#             if v.lower() == 'yes':\n",
    "#                 items.append((new_key, 1))\n",
    "#             elif v.lower() == 'no':\n",
    "#                 items.append((new_key, 0))\n",
    "#             else:\n",
    "#                 newer_key = (new_key + sep + str(v))\n",
    "#                 items.append((newer_key, 1)) \n",
    "#         elif isinstance(v,(int,float)):\n",
    "#             items.append((new_key, v)) \n",
    "\n",
    "#     return dict(items)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class DictFlatten(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "#     def fit(self, X, y = None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         # X will be a pandas series. Return a pandas series of dictionaries\n",
    "#         return pd.Series([dict_flattener(j) for j in X.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping\n",
    "\n",
    "def dict_flattener(X: MutableMapping, parent_key = ''):\n",
    "    sep = '_'\n",
    "    items= []\n",
    "    for k, v in X.items():\n",
    "        new_key = (parent_key + sep + str(k)) if parent_key else str(k)\n",
    "        if isinstance(v, MutableMapping):\n",
    "            items.extend(dict_flattener(v, parent_key=new_key).items())\n",
    "        elif isinstance(v,bool):\n",
    "            items.append((new_key, int(v)))\n",
    "        elif isinstance(v,str):\n",
    "            if v.lower() == 'yes':\n",
    "                items.append((new_key, 1))\n",
    "            elif v.lower() == 'no':\n",
    "                items.append((new_key, 0))\n",
    "            else:\n",
    "                newer_key = (new_key + sep + str(v))\n",
    "                items.append((newer_key, 1)) \n",
    "        elif isinstance(v,(int,float)):\n",
    "            items.append((new_key, v)) \n",
    "\n",
    "    return dict(items)\n",
    "\n",
    "\n",
    "\n",
    "class DictFlatten(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return pd.Series([dict_flattener(j) for j in X.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# date_transformer = FunctionTransformer(dict_flattener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dict_vectorizer = Pipeline([\n",
    "        ('DictFlatten',DictFlatten()),\n",
    "        (' DictVectorizer', DictVectorizer())\n",
    "], verbose=True)\n",
    "\n",
    "\n",
    "cat_transformer_att = ColumnTransformer([\n",
    "    ('dict_vectorize', dict_vectorizer, ['attributes'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 3) Processing to_df, total=   0.2s\n",
      "[Pipeline] ....... (step 1 of 2) Processing DictFlatten, total=   0.5s\n",
      "[Pipeline] ... (step 2 of 2) Processing  DictVectorizer, total=   0.5s\n",
      "[Pipeline] ... (step 2 of 3) Processing cat_transformer, total=   1.0s\n",
      "[Pipeline] ........ (step 3 of 3) Processing ridge_grid, total=  21.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('to_df', ToDataFrame()),\n",
       "                ('cat_transformer',\n",
       "                 ColumnTransformer(transformers=[('dict_vectorize',\n",
       "                                                  Pipeline(steps=[('DictFlatten',\n",
       "                                                                   DictFlatten()),\n",
       "                                                                  (' '\n",
       "                                                                   'DictVectorizer',\n",
       "                                                                   DictVectorizer())],\n",
       "                                                           verbose=True),\n",
       "                                                  ['attributes'])])),\n",
       "                ('ridge_grid', GradientBoostingRegressor(n_estimators=1000))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "\n",
    "n_alphas = 50\n",
    "alphas = np.logspace(-10, 3, n_alphas)\n",
    "\n",
    "parameters = {'alpha': alphas}\n",
    "ridge_ = Ridge()\n",
    "ridge_grid = GridSearchCV(ridge_, parameters)\n",
    "\n",
    "\n",
    "\n",
    "lr_att_model = Pipeline([\n",
    "        ('to_df',to_data_frame),\n",
    "        ('cat_transformer',cat_transformer_att),\n",
    "#         ('TfidfTransformer',TfidfTransformer()),\n",
    "        ('ridge_grid',GradientBoostingRegressor(n_estimators=1000))\n",
    "], verbose=True)\n",
    "\n",
    "\n",
    "att_model_lr = lr_att_model\n",
    "\n",
    "att_model_lr.fit(data, star_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.90494074, 3.56955625, 3.81880401, ..., 3.68451971, 3.99400936,\n",
       "       3.67765768])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_model_lr.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# rf_regressor_nlr = RandomForestRegressor()\n",
    "\n",
    "# rf_regressor = rf_regressor_nlr\n",
    "# rf_regressor.fit(prediction.reshape(-1, 1), star_ratings)\n",
    "\n",
    "# star_ratings - rf_regressor.predict(residual.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# model = DecisionTreeRegressor()\n",
    "# model.fit(residual.reshape(-1, 1), star_ratings)\n",
    "\n",
    "# star_ratings - model.predict(residual.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # n_alphas = 50\n",
    "# # # alphas = np.logspace(-10, 3, n_alphas)\n",
    "\n",
    "# # # parameters = {'alpha': alphas}\n",
    "# # # ridge_ = Ridge()\n",
    "# # # ridge_grid = GridSearchCV(ridge_, parameters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class EnsemblePredictor(BaseEstimator, RegressorMixin):\n",
    "#     def fit(self, X, y):\n",
    "#         lr_att_model = Ridge(alpha=7.543120063354638)\n",
    "#         lr_att_model.fit(X,y)\n",
    "#         prediction = lr_att_model.predict(X)\n",
    "#         residual = (y - prediction)\n",
    "#         rf_regressor_nlr = RandomForestRegressor()\n",
    "# #         rf_regressor_nlr.fit(residual, y)\n",
    "#         return rf_regressor_nlr.fit(residual.reshape(-1, 1),y)\n",
    "    \n",
    "#     def predict(self, X):\n",
    "\n",
    "#         return rf_regressor_nlr.predict(X.reshape(-1, 1))\n",
    "    \n",
    "    \n",
    "    \n",
    "# lr_att_model_en = Pipeline([\n",
    "#         ('to_df',to_data_frame),\n",
    "#         ('cat_transformer',cat_transformer_att),\n",
    "# #         ('TfidfTransformer',TfidfTransformer()),\n",
    "#         ('EnsemblePredictor',EnsemblePredictor())\n",
    "# ], verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_att_model_en.fit(data,star_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the transformer to handle the attributes data\n",
    "\n",
    "# Create the linear + non-linear ensemble predictor\n",
    "\n",
    "# Create the attribute model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Question 6: full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "So far we have only built models based on individual features.  Now we will build an ensemble regressor that averages together the estimates of the four previous regressors.\n",
    "\n",
    "In order to use the existing models as input to a predictor, we will have to turn them into transformers; a predictor can only be in the final step of a pipeline. Build a custom `ModelTransformer` class that takes a predictor as an argument. When `fit` is called, the predictor should be fit. When `transform` is called, the predictor's `predict` method should be called, and its results returned as the transformation.\n",
    "\n",
    "Note that the output of the `transform` method should be a 2-D array with a single column in order for it to work well with the scikit-learn pipeline. If you're using NumPy arrays, you can use `.reshape(-1, 1)` to create a column vector. If you are just using Python lists, you will want a list of lists of single elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class ModelTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        # What needs to be done here?\n",
    "        self.model = model\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X,y)\n",
    "        # Fit the stored predictor.\n",
    "        # Question: what should be returned?\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Use predict on the stored predictor as a \"transformation\".\n",
    "        # Be sure to return a 2-D array.\n",
    "        return np.array(self.model.predict(X)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Let's now test it out on our `city_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_trans = ModelTransformer(city_model)\n",
    "city_trans.fit(data, star_ratings)\n",
    "X_t = city_trans.transform(data[:5])\n",
    "\n",
    "# Check that the transformation output is a 2-D array with one column\n",
    "grader.check(np.array(X_t).shape[-1] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array(city_model.predict(data[:5]))\n",
    "\n",
    "# Check that the transformation output is the same as the model's predictions\n",
    "grader.check((y_pred.reshape(-1, 1) == X_t).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Create an instance of `ModelTransformer` for each of the previous four models. Combine these together in a single feature matrix with a\n",
    "[`FeatureUnion`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "city_trans = ModelTransformer(city_model)\n",
    "lat_long_trans = ModelTransformer(lat_long_to_star_ratings)\n",
    "category_trans = ModelTransformer(category_model)\n",
    "att_trans = ModelTransformer(att_model_lr)\n",
    "\n",
    "\n",
    "union = FeatureUnion([\n",
    "    ('city_trans',city_trans),\n",
    "    ('lat_long_to_star_ratings',lat_long_trans),\n",
    "    ('category_model',category_trans),\n",
    "    ('attribute_model',att_trans)\n",
    "        # FeatureUnion uses the same syntax as Pipeline\n",
    "    ], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Our `FeatureUnion` object should return a feature matrix with four columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FeatureUnion] .... (step 1 of 4) Processing city_trans, total=   0.0s\n",
      "[Pipeline] ............. (step 1 of 3) Processing to_df, total=   0.2s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing knn_regressor_grid, total=  20.8s\n",
      "[FeatureUnion]  (step 2 of 4) Processing lat_long_to_star_ratings, total=  21.0s\n",
      "[Pipeline] ............. (step 1 of 4) Processing to_df, total=   0.2s\n",
      "[Pipeline] ....... (step 1 of 2) Processing DictEncoder, total=   0.0s\n",
      "[Pipeline] ... (step 2 of 2) Processing  DictVectorizer, total=   0.1s\n",
      "[Pipeline] ... (step 2 of 4) Processing cat_transformer, total=   0.2s\n",
      "[Pipeline] .. (step 3 of 4) Processing TfidfTransformer, total=   0.0s\n",
      "[Pipeline] ........ (step 4 of 4) Processing ridge_grid, total=  17.9s\n",
      "[FeatureUnion]  (step 3 of 4) Processing category_model, total=  18.3s\n",
      "[Pipeline] ............. (step 1 of 3) Processing to_df, total=   0.2s\n",
      "[Pipeline] ....... (step 1 of 2) Processing DictFlatten, total=   0.5s\n",
      "[Pipeline] ... (step 2 of 2) Processing  DictVectorizer, total=   0.5s\n",
      "[Pipeline] ... (step 2 of 3) Processing cat_transformer, total=   1.0s\n",
      "[Pipeline] ........ (step 3 of 3) Processing ridge_grid, total=  21.3s\n",
      "[FeatureUnion]  (step 4 of 4) Processing attribute_model, total=  22.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FeatureUnion(transformer_list=[('city_trans',\n",
       "                                ModelTransformer(model=CityRegressor())),\n",
       "                               ('lat_long_to_star_ratings',\n",
       "                                ModelTransformer(model=Pipeline(steps=[('to_df',\n",
       "                                                                        ToDataFrame()),\n",
       "                                                                       ('selector',\n",
       "                                                                        ColumnTransformer(transformers=[('lat_long',\n",
       "                                                                                                         'passthrough',\n",
       "                                                                                                         ['latitude',\n",
       "                                                                                                          'longitude'])])),\n",
       "                                                                       ('knn_regressor_grid',\n",
       "                                                                        GridSearchCV(cv=KFold(n_splits=5, random_state=1169, s...\n",
       "                               ('attribute_model',\n",
       "                                ModelTransformer(model=Pipeline(steps=[('to_df',\n",
       "                                                                        ToDataFrame()),\n",
       "                                                                       ('cat_transformer',\n",
       "                                                                        ColumnTransformer(transformers=[('dict_vectorize',\n",
       "                                                                                                         Pipeline(steps=[('DictFlatten',\n",
       "                                                                                                                          DictFlatten()),\n",
       "                                                                                                                         (' '\n",
       "                                                                                                                          'DictVectorizer',\n",
       "                                                                                                                          DictVectorizer())],\n",
       "                                                                                                                  verbose=True),\n",
       "                                                                                                         ['attributes'])])),\n",
       "                                                                       ('ridge_grid',\n",
       "                                                                        GradientBoostingRegressor(n_estimators=1000))],\n",
       "                                                                verbose=True)))],\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union.fit(data, star_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = union.transform(data[:5])\n",
    "\n",
    "# Transformed data should have 5 rows and 4 columns\n",
    "grader.check(X_t.shape == (5, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Finally, use a pipeline to combine the feature union with a linear regression (or another model) to weight the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FeatureUnion] .... (step 1 of 4) Processing city_trans, total=   0.1s\n",
      "[Pipeline] ............. (step 1 of 3) Processing to_df, total=   0.2s\n",
      "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "full_model = Pipeline([\n",
    "        ('union_model',union),\n",
    "#         ('random_forest_regressor',RandomForestRegressor())\n",
    "        ('linear_regressor',LinearRegression())\n",
    "], verbose=True)\n",
    "\n",
    "\n",
    "full_model.fit(data, star_ratings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbclean": true,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
